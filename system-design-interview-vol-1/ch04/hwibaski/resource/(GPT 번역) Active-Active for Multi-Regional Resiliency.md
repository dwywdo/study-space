> 원문: https://netflixtechblog.com/active-active-for-multi-regional-resiliency-c47719f6685b

글쓴이: Ruslan Meshenberg, Naresh Gopalani, Luke Kosewski

지난 6월, 우리는 **Isthmus**라는 프로젝트에 대해 이야기했습니다. 이 프로젝트는 지역 전체의 ELB(Elastic Load Balancer) 장애에 대한 복원력을 확보하기 위한 Netflix의 접근 방식이었습니다. Isthmus 프로젝트를 마무리한 후, 우리는 더 높은 수준의 복원력과 가용성을 추구하기 위한 다음 단계로 나아갔습니다. 바로 **완전한 다중 지역 Active-Active 솔루션**이었습니다. 이 프로젝트는 이제 완료되었고, Netflix는 미국 전역에서 Active-Active 구조로 운영되고 있습니다. 이 글에서는 우리가 이 과정에서 마주한 흥미로운 도전 과제들과 배운 점들을 공유하고자 합니다.

## 실패 — 규모와 속도의 함수

일반적으로, 조직이 겪는 실패율은 크게 두 가지 요인에 따라 달라집니다: **운영 배포의 규모**와 **변화의 속도**입니다. 규모와 속도가 모두 작을 경우, 대부분의 경우 시스템은 별 문제 없이 잘 동작합니다. 그러나 배포 규모가 커지기 시작하면, 변화 속도가 느리더라도 **하드웨어 장애**의 가능성이 증가하게 됩니다. 반대로, 규모는 작더라도 변화 속도가 빠르면 **소프트웨어 오류**의 가능성이 높아집니다. 결국 규모가 크고 빠른 속도로 변화하고 있다면 — 시스템은 **언제든지 장애를 겪을 수 있습니다.**

물론, 모든 실패가 동일한 수준으로 심각한 것은 아닙니다. 이 글에서 우리가 집중하고자 하는 실패 유형은 가장 중요하면서도 다루기 어려운 것들입니다 — 즉, **완전하고 장기적인 서비스 중단**입니다. 이는 고객들이 고객센터로 몰려들고, 불만을 트위터에 쏟아내며, 여러 언론에 “서비스 X 접속 불가!”라는 기사가 실리는 상황을 의미합니다.

Netflix는 내부적으로 **99.99%의 가용성**을 목표로 하고 있습니다 — 이는 서비스가 중단될 수 있는 여지를 거의 주지 않는 수준입니다. 그래서 우리는 서비스를 여러 인스턴스와 **가용 영역(Availability Zone)**에 분산 배포하는 것에 더해, **여러 AWS 리전(Region)**에까지 배포하기로 결정했습니다. 전체 리전의 인프라가 동시에 마비되는 상황은 극히 드물지만, 빠른 변화 속도는 때때로 한 리전 내의 핵심 서비스를 망가뜨릴 수 있습니다. 우리는 Netflix가 이러한 **기반 의존성 장애에도 견딜 수 있도록 만들고자** 했습니다.

이를 위해 우리는 **격리(Isolation)**와 **중복(Redundancy)**이라는 원칙을 활용합니다. 한 리전에서 발생한 어떠한 실패도 **다른 리전에서 동작 중인 서비스에는 영향을 미쳐서는 안 되며**, 네트워크 단절 상황이 발생해도 **각 리전의 서비스 품질은 유지되어야 합니다.**

## Active-Active 개요

간단히 말해, **Active-Active** 솔루션이란 **사용자 요청 경로 상의 모든 서비스들을 여러 AWS 리전에 걸쳐 배포**하는 것을 의미합니다. Netflix의 경우, **미국 동부(Virginia)의 US-East-1** 리전과 **미국 서부(Oregon)의 US-West-2** 리전에 서비스가 배포되어 있습니다. 이를 실현하기 위해 다음과 같은 **조건들이 충족되어야 합니다**:

1. **서비스는 상태 비저장(stateless)이어야 합니다.**  
   모든 데이터 및 상태 복제는 데이터 계층에서 처리되어야 합니다.
2. **모든 리소스는 리전 내에서만 접근해야 합니다.**  
   예를 들어, S3, SQS 등의 리소스를 사용하는 애플리케이션들은 단일 S3 버킷이 아닌, **각 리전에 존재하는 별도의 S3 버킷에 데이터를 따로 게시해야 합니다.**
3. **사용자 요청 경로에 리전 간 호출이 있어서는 안 됩니다.**  
   데이터 복제는 반드시 **비동기적으로(asynchronous)** 이루어져야 합니다.

정상 상태에서는, **Geo DNS**를 통해 사용자가 지리적으로 가장 가까운 리전으로 라우팅되며, 일반적으로 **미국 동부와 서부가 50:50 비율로** 나뉘어 트래픽을 처리합니다. 그러나 **특정 리전 전체에 걸친 심각한 장애가 발생할 경우**, 우리는 **Geo DNS 설정을 수동으로 오버라이드**하여 모든 트래픽을 정상적으로 운영 중인 리전으로 전환할 수 있는 도구들을 보유하고 있습니다.

![](./Pasted%20image%2020250412163943.png)

### 이러한 구조를 구현하기 위한 기술적 도전 과제들

- **정확한 리전으로 트래픽을 라우팅하기 위한 효과적인 도구**
- **트래픽 셰이핑(Traffic Shaping)** 및 **과부하 방지(Load Shedding)** 전략 → 특정 시간대에 트래픽이 집중되는 **“떼 지어 몰려드는” 상황(thundering herd)**을 견디기 위해 필요
- **비동기 방식의 리전 간 상태/데이터 복제**

## DNS — Denominator를 통한 사용자 트래픽 제어

우리는 사용자 트래픽을 Netflix 서비스로 라우팅하기 위해 **UltraDNS**와 **Route53**을 조합하여 사용하고 있으며, 이 과정을 제어하는 데 사용되는 도구가 바로 Netflix의 **Denominator** 프로젝트입니다.  
Denominator는 여러 DNS 공급자를 하나의 클라이언트 라이브러리와 명령어 인터페이스로 통합하여 제어할 수 있도록 해줍니다.

우리가 두 가지 DNS 공급자를 조합해서 사용하게 된 이유는 다음과 같습니다:

1. **UltraDNS는 지리 기반 트래픽 라우팅 기능을 제공합니다.**  
   북미의 서로 다른 지역에 있는 사용자들을 **다른 리전 엔드포인트로 방향성 있게 라우팅**할 수 있게 해줍니다. 이 기능은 Dyn과 같은 일부 다른 벤더들도 제공하지만, **Route53에서는 지원되지 않습니다.**  
   우리는 **지연 시간(latency) 기반 라우팅 방식은 사용하지 않기로 했는데**, 그 이유는 예측 불가능한 트래픽 이동 현상이 발생할 수 있기 때문입니다.
2. **UltraDNS와 ELB 사이에 Route53 레이어를 삽입함으로써,**  
   우리는 **사용자 트래픽을 전환할 수 있는 추가적인 수단**을 확보하게 됩니다.  
   특히, **Route53의 API는 빠르고 안정적인 구성 변경 기능을 제공**하는 반면, **다른 DNS 공급자들의 API는 이런 부분이 약점**인 경우가 많습니다.
3. **트래픽 전환을 Route53 레이어에서 수행하면 훨씬 간단해집니다.**  
   지역 그룹을 조작하여 영역 전체를 이동시키는 대신, **그저 Route53의 CNAME 레코드를 이동시키는 것만으로도 트래픽 라우팅을 변경**할 수 있습니다.

![](./Pasted%20image%2020250412164235.png)

## Zuul — 트래픽 셰이핑(Traffic Shaping)

우리는 최근 Zuul에 대해 자세히 설명한 바 있으며, 이는 2013년 6월 커뮤니티에 이 컴포넌트를 오픈하면서 다룬 내용입니다. 현재 Netflix의 모든 엣지(Edge) 서비스는 Zuul 레이어를 앞단에 두고 있습니다. Zuul은 적절한 서비스 클러스터로 트래픽을 유연하고 견고하게 라우팅할 수 있는 기능, 런타임 중 라우팅을 변경할 수 있는 기능, 그리고 하위 서비스가 과부하되는 것을 방지하기 위해 일부 부하를 차단할지를 결정할 수 있는 기능 등을 제공합니다.

Active-Active 구성 및 운영상 필요를 충족시키기 위해, 우리는 Zuul을 원래의 기능보다 확장해야 했습니다. 이러한 확장은 다음과 같은 영역에서 이루어졌습니다:

- **잘못 라우팅된 요청을 식별하고 처리하는 기능**: 사용자 요청이 지리적 라우팅 규칙(geo directional records)에 부합하지 않으면 잘못 라우팅된 것으로 간주됩니다. 이 기능은 하나의 사용자 기기 세션이 여러 지역에 걸쳐 분산되지 않도록 보장합니다. 또한, 잘못 라우팅된 요청을 올바른 AWS 리전으로 보내는 "isthmus 모드"를 사용할지, 혹은 클라이언트에게 올바른 리전으로 리디렉션하는 응답을 보낼지를 제어할 수 있는 설정도 존재합니다.
- **리전을 "페일오버(failover)" 모드로 선언하는 기능**: 이 모드에서는 더 이상 잘못 라우팅된 요청을 다른 리전으로 보내지 않고, 로컬에서 처리하게 됩니다.
- **동시 트래픽의 최대 수준을 정의하는 기능**: 이를 통해 설정된 트래픽 한도를 초과하는 요청은 자동으로 거절(오류 응답)되며, 이는 하위 서비스가 요청 폭주로 인해 과부하되지 않도록 보호하는 데 매우 중요합니다. 특히, 수요 증가로 인해 서비스가 확장 중이거나, 지역 캐시가 비워진 상태(콜드 캐시)에서 하위 저장 계층에 과도한 부하가 가해지는 것을 방지할 수 있습니다.

이 모든 기능들은 안정적인 상태에서든, 장애 상황(failover)에서든, 사용자의 트래픽을 효과적으로 제어할 수 있도록 강력하고 유연한 도구 세트를 제공합니다.

## 데이터 복제 — Cassandra와 EvCache

Active-Active 구성을 구현하면서 가장 흥미로운 도전 과제 중 하나는 **사용자의 데이터/상태를 복제하는 문제**였습니다. Netflix는 확장성과 복원력이 뛰어난 NoSQL 영속성 솔루션으로 **Apache Cassandra**를 채택해 왔습니다. Apache Cassandra의 본질적인 기능 중 하나는 **양방향 및 다중 데이터센터(다중 리전) 비동기 복제** 기능입니다. 이러한 이유로, 사용자 요청을 처리하기 위해 읽고 쓰는 모든 데이터는 Apache Cassandra에 저장됩니다.

Netflix는 Active-Active를 도입하기 이전에도 US-EAST-1과 EU-WEST-1 리전에 걸쳐 **다중 리전 Cassandra 클러스터**를 운영해 왔습니다. 그러나 그 클러스터에 저장된 대부분의 데이터는 결국 다른 리전으로 복제되긴 하지만, **작성된 리전에서 소비**되는 것이 일반적이었습니다. 이때는 주로 `CL_LOCAL_QUORUM` 또는 `CL_ONE`과 같은 일관성(consistency) 수준으로 처리되었고, **지연(latency)은 큰 문제가 되지 않았습니다.**

하지만 Active-Active는 이러한 사용 방식을 바꿔 놓았습니다. 요청이 US 어느 리전에서든 들어올 수 있는 상황에서, 데이터 복제가 **허용 가능한 시간 내에 완료**되어야만 했습니다. 이를 검증하기 위해 다음과 같은 실험을 진행했습니다:

- 다중 리전 Cassandra 클러스터의 한 리전에 **100만 건의 레코드**를 작성(writing)했습니다.
- 500ms 후, 다른 리전에서 **이전 리전에서 작성한 레코드를 읽는(reading)** 작업을 수행했습니다.
- 이 실험은 실제 서비스 수준의 부하 하에서 수행되었습니다.

그 결과, **모든 레코드가 성공적으로 읽혀졌습니다.** 이 테스트는 모든 오류 상황이나 극단적인 케이스를 포함한 **완전한 테스트**는 아니었지만, Netflix의 사용 사례에 있어 **Apache Cassandra의 일관성과 시간 내 복제 능력**에 대한 충분한 신뢰를 제공해주었습니다.

![](./Pasted%20image%2020250414090328.png)

많은 사용자 요청을 처리하는 애플리케이션들이 **정해진 시간 내에 응답해야 하기 때문에**, 데이터 계층에서의 **읽기 속도는 매우 빨라야 하며**, 일반적으로 **1밀리초 단위의 속도**가 요구됩니다. 일부 경우에는 **Cassandra 클러스터 앞단에 Memcached 계층**을 두기도 하고, 다른 경우에는 **Memcached에만 존재하는 일시적인 계산 데이터**를 사용하기도 합니다.

하지만 **다중 리전 Active-Active 환경에서 Memcached를 관리**하는 것은 **원본 데이터와 캐시 간의 일관성을 유지**하는 과제를 동반합니다. 이를 위해 Memcached용으로 멀티 마스터 복제 기능을 새로 구현하기보다는, **EvCache 클라이언트**(Netflix가 2013년 초에 오픈소스로 공개한 Memcached 클라이언트 라이브러리)에 **원격 캐시 무효화 기능**을 추가했습니다.

즉, **한 리전에서 쓰기 작업이 발생하면**, EvCache 클라이언트는 **SQS를 통해 다른 리전에 메시지를 보내어 해당 캐시 항목을 무효화**합니다. 따라서 **다른 리전에서의 이후 읽기 작업은** 데이터를 재계산하거나 Cassandra에서 읽어와 **로컬 캐시를 다시 갱신하게 됩니다.**

- **Cassandra = 글로벌 확장성과 신뢰성 있는 데이터 복제**
- **EvCache = 다중 리전 환경에서의 캐시 일관성 보완 도구**
- **SQS = 리전 간 통신을 위한 메시지 브로커 역할**

## 여러 환경과 리전에 걸친 배포 자동화

2012년 EU에서 서비스를 출시했을 때, 우리의 배포 환경은 두 개에서 네 개로 늘어났습니다: 테스트와 프로덕션, US-East와 EU-West. 이와 유사하게, 북미 서비스를 Active-Active 모드로 배포하기로 결정하면서 배포 환경은 여섯 개로 증가했습니다 — US-West 리전에 테스트와 프로덕션이 추가된 것입니다. 개별 배포에는 매우 강력하고 유연한 배포 및 설정 콘솔인 Asgard를 사용하지만, 우리는 곧 개발자들이 모든 리전에서 서비스를 일관되게 유지하기 위해 최소 6단계(일부 애플리케이션은 더 많은 “버전”을 지원함)의 수동 배포 과정을 거치는 것은 바람직하지 않다는 것을 깨달았습니다.

다중 리전에 걸친 배포 과정을 보다 자동화하기 위해, 우리의 Tools 팀은 오픈소스 Glisten 워크플로 언어를 기반으로 한 Mimir라는 워크플로 도구를 개발했습니다. Mimir는 개발자가 다중 리전 배포 대상을 정의하고, 언제 어떻게 배포할지를 규칙으로 지정할 수 있게 해줍니다. 이 도구는 자동 캐너리 분석 및 자동 롤백 절차와 결합되어, 여러 지역에 순차적인 단계로 애플리케이션을 자동으로 배포할 수 있도록 합니다. 일반적으로 우리는 리전 간 업데이트 사이에 여러 시간을 기다리며, 전 세계에 배포하기 전에 문제를 감지할 수 있도록 합니다.

## Monkeys — Gorilla, Kong, Split-brain

우리는 시스템을 ‘망가뜨리기 위해’ 사용하는 다양한 몽키 도구들의 집합인 **Simian Army**에 대해 자주 이야기해왔습니다. 이는 다양한 장애 상황에 대해 서비스들이 얼마나 탄력적인지를 검증하고, 시스템을 더욱 **안티프래질(anti-fragile)**하게 만들 수 있는 방법을 배우기 위함입니다.  
가장 유명한 Simian Army 멤버 중 하나인 **Chaos Monkey**는 테스트 및 프로덕션 환경 모두에서 실행되며, 최근에는 **Cassandra 클러스터도 대상**에 포함되고 있습니다.

더 큰 규모의 장애에 시스템이 견딜 수 있는지를 검증하기 위해, 우리는 보다 강력한 몽키들을 투입했습니다:

- **Chaos Gorilla**: 하나의 **가용 영역(Availability Zone)** 전체를 중단시켜, 나머지 가용 영역들이 서비스 품질 저하 없이 사용자 요청을 계속 처리할 수 있는지를 확인합니다. Active-Active 구성 이전에도 Gorilla를 실행했지만, 정기적인 반복 테스트를 통해 새로운 아키텍처도 영역 단위의 장애에 견딜 수 있음을 확인했습니다.
- **Split-brain**: **리전 간의 네트워크 연결을 끊는** 새로운 유형의 장애 시뮬레이션입니다. 이는 일부 데이터 복제가 지연되더라도, 각 리전의 서비스가 **정상적으로 작동**하는지를 확인하기 위함입니다. Active-Active 프로젝트 기간 동안 여러 차례 Split-brain 시뮬레이션을 수행했고, 그 과정에서 다양한 문제를 발견하고 수정할 수 있었습니다.
- **Chaos Kong**: 지금까지 시도한 가장 **대규모 장애 시뮬레이션**입니다. 실제 상황에서는, 심각한 장애 발생 시 **사용자 트래픽을 다른 리전으로 신속히 전환**하게 되며, 이로 인해 일부 사용자들이 서비스 품질 저하나 완전한 서비스 중단을 경험할 수 있습니다. 하지만 시뮬레이션에서는 **사용자 경험 저하 없이** 테스트하는 것이 목적이었기에, 실패한 리전으로 라우팅된 사용자들도 **정상적인 리전으로 리디렉션**될 수 있도록 조치했습니다.
  또한, 실제 긴급 상황에서보다 **점진적으로 트래픽을 이동**시켜 서비스가 적절히 스케일 업되고 캐시가 점진적으로 워밍업될 수 있도록 했습니다. 모든 트래픽 소스를 전환한 것은 아니었지만, **대부분을 전환함으로써 US-West-2 리전이 Netflix 전체 트래픽을 감당할 수 있음을 입증**했습니다. 우리는 서부 리전에 트래픽을 **24시간 이상 유지한 후**, 다시 **안정적인 50/50 상태로 점진적으로 복귀**시켰습니다. 아래 그래프에서는 이러한 실험의 모습을 볼 수 있으며, 대부분의 트래픽이 US-East에서 US-West로 이동했으며, EU-West 리전은 영향을 받지 않았습니다.

![](./Pasted%20image%2020250414091258.png)

**실제 장애 조치(Failover) 사례**

Chaos Kong을 통해 다지역 간의 격리성과 이중화가 완전히 검증되기 전임에도 불구하고, 우리는 **실제 상황에서 지역 장애 조치를 수행할 기회**를 얻게 되었습니다.  
한 리전의 **미들 티어 시스템 중 하나에서 심각한 성능 저하**가 발생했고, 결국 클러스터 대부분이 응답하지 않는 상황에 이르렀습니다. 일반적인 상황이었다면 이는 심각한 서비스 중단으로 이어졌을 것이며, 많은 사용자들이 일정 시간 동안 영향을 받았을 것입니다.

하지만 이번에는 **우리가 사용할 수 있는 추가 도구**가 있었고, 우리는 **장애 조치(failover)를 실행**하여 사용자 요청을 **건강한 리전으로 우회**시키기로 결정했습니다.  
그 결과, **짧은 시간 내에 모든 사용자에게 서비스 품질이 복구**되었습니다. 이후 우리는 문제의 **근본 원인을 분석**하고, **수정 사항을 배포한 뒤**, 트래픽을 **정상화된 리전으로 다시 전환**할 수 있었습니다.

아래는 장애 조치의 타임라인을 나타낸 것이며, 검은 선은 **1주일 전의 기준선**을 참고로 표시한 것입니다.

![](./Pasted%20image%2020250414091345.png)

**가용성 향후 계획**

위에서 설명한 Active-Active 프로젝트의 모든 작업은 **시작에 불과**합니다. 이 프로젝트는 아직 **2단계**가 남아 있으며, 이 단계에서는 **다중 지역 도구의 운영 측면에 집중**하고, 현재의 수동 단계를 가능한 한 많이 **자동화**할 것입니다. 또한, **장애 조치를 실행할 결정을 내리는 시간과 모든 트래픽을 장애 조치하는 데 걸리는 시간을 최소화**하는 데 집중할 것입니다.

우리는 또한 **더 어려운 문제들**에 대한 해결을 계속해서 추진하고 있습니다. 예를 들어, **일부 종속성이 느리게 응답하거나 오류를 반환할 때**, 그 오류가 **일시적으로만 발생**하는 상황을 어떻게 처리할 것인가가 그 예입니다. 이러한 문제는 **Chaos** 유형의 시나리오를 다루는 것보다 더 어려운 문제일 수 있습니다. 왜냐하면 어떤 것이 **없거나 지속적으로 실패**할 때는 무엇을 해야 할지 결정하기가 더 쉬워지기 때문입니다.  
이러한 시나리오에서 우리의 시스템이 어떻게 동작하는지 배우기 위해 우리는 **Latency Monkey**를 사용하고 있습니다. 이 도구는 **주어진 빈도와 분포**에 따라 **클라이언트 및 서버 측**에서 **지연과 오류**를 주입할 수 있습니다.

## 요약

대규모와 빠른 속도에는 실패의 가능성도 증가합니다. **격리**와 **중복**의 원칙을 활용하여 우리는 아키텍처를 보다 **넓은 범위의 장애에 견디도록** 만들었습니다. 우리가 서비스를 구성하고 이를 복원력 있게 만드는 데 사용하는 기본 구성 요소들은 우리의 **OSS Github 사이트**에서 확인할 수 있으며, **Active-Active**와 관련된 대부분의 변경 사항은 이미 제공되고 있고, 일부는 소스 코드를 업데이트하기 전에 코드 리뷰를 거치고 있습니다.

이 글에서는 **Active-Active**에 대한 기술적 도전과 해결책을 설명했습니다. 비기술적인 수준의 복잡성은 훨씬 더 어려웠습니다. 특히 여러 중요한 프로젝트들이 동시에 진행되고 있었기 때문에 더욱 그렇습니다. 성공의 비결은 **Netflix에서 일하는 놀라운 팀들**과 **US-West-2에서 빠르게 추가 용량을 제공할 수 있는 AWS**의 능력에 있었습니다. 모든 팀들이 함께 협력한 덕분에 이 프로젝트는 몇 달 만에 끝낼 수 있었습니다.

비슷한 도전과 훌륭한 팀들과 함께 일할 기회에 흥미가 있다면, **우리의 채용 사이트**를 확인해보세요. 우리는 Netflix 서비스를 더 복원력 있고 가용성 높게 만들기 위해 함께할 뛰어난 엔지니어를 찾고 있습니다!
